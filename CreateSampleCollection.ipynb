{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"/nas/Datasets/trec_ct\"\n",
    "part = 'ClinicalTrials.2021-04-27.part1'\n",
    "folder = \"NCT0000xxxx/\" # dependent on the 'part' folder\n",
    "file = os.path.join(dataset_root,part,folder,'NCT01607801.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_simple_doc(root : xml.etree.ElementTree.Element) -> dict:\n",
    "    \"\"\"\n",
    "    Columns that comprise a doc:\n",
    "        'id' using nct_id\n",
    "        'summary' using brief_summary\n",
    "        'gender' using eligibility.gender\n",
    "        'min_age' using eligibility.minimum_age\n",
    "        'max_age' using eligibility.maximum_age\n",
    "    \"\"\"\n",
    "    try:\n",
    "        id_ = root.find('id_info').find('nct_id').text\n",
    "        title = root.find('brief_title').text\n",
    "        summary = root.find('brief_summary')[0].text\n",
    "        gender = root.find('eligibility').find('gender').text\n",
    "        min_age = root.find('eligibility').find('minimum_age').text\n",
    "        max_age = root.find('eligibility').find('maximum_age').text\n",
    "\n",
    "        doc = {'id':id_,'title':title, 'summary':summary,'gender':gender,'min_age':min_age,'max_age':max_age}\n",
    "    except:\n",
    "        doc = None\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 1000/5000\n",
      "Progress 2000/5000\n",
      "Progress 3000/5000\n",
      "Progress 4000/5000\n",
      "Progress 5000/5000\n",
      "NCT0000xxxx\n",
      "NCT00002067.xml\n",
      "Success!\n",
      "ignored docs: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_collection_sample_to_csv(dataset_root, part, save_path, max_collection_size):\n",
    "    \"\"\"\n",
    "    Creates a sample of max_collection_size documents in a csv format.\n",
    "    Current version is not even a real saple as it generates docs in an orderly manner.\n",
    "    \n",
    "    Supported columns are defined in the function <gen_simple_doc>\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    ignored_docs = 0\n",
    "\n",
    "    i = 0\n",
    "    stop = False\n",
    "    part_path = os.path.join(dataset_root,part)\n",
    "\n",
    "    for folder in os.listdir(part_path):\n",
    "        folder_path = os.path.join(part_path,folder)\n",
    "        files = os.listdir(folder_path)\n",
    "        for file in files:\n",
    "            filepath = os.path.join(folder_path,file)\n",
    "\n",
    "            # read and parse file\n",
    "            root = ET.parse(filepath).getroot()\n",
    "            doc = gen_simple_doc(root)\n",
    "\n",
    "            if not doc:\n",
    "                ignored_docs +=1\n",
    "                continue\n",
    "\n",
    "            docs.append(doc)\n",
    "            i +=1\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f'Progress {i}/{max_collection_size}')\n",
    "\n",
    "            if i == max_collection_size:\n",
    "                print(folder)\n",
    "                print(file)\n",
    "                stop = True\n",
    "                break\n",
    "\n",
    "\n",
    "        if stop:\n",
    "            break\n",
    "    print('Success!')\n",
    "    print(f'ignored docs: {ignored_docs}')\n",
    "    \n",
    "    df = pd.DataFrame(docs)\n",
    "    df.to_csv(save_path,index=False)\n",
    "    return True\n",
    "\n",
    "create_collection_sample_to_csv(dataset_root, part,'data/5ksample.csv',5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
